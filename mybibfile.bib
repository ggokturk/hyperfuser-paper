@article{Dirac1953888,
  title   = "The lorentz transformation and absolute time",
  journal = "Physica ",
  volume  = "19",
  number  = "1-–12",
  pages   = "888--896",
  year    = "1953",
  author  = "P.A.M. Dirac"
}

@article{edges,
  author={D. {Yang} and J. {Liu} and J. {Lai}},
  journal={IEEE Tran. on Parallel and Dist. Sys.}, 
  title={{EDGES}: An Efficient Distributed Graph Embedding System on {GPU} clusters}, 
  year={2020},
  volume={},
  number={},
  pages={1-1},
}


@article{Feynman1963118,
  title   = "The theory of a general quantum system interacting with a linear dissipative system",
  journal = "Annals of Physics ",
  volume  = "24",
  pages   = "118--173",
  year    = "1963",
  author  = "R.P Feynman and F.L {Vernon Jr.}"
}

@inproceedings{graphvite19,
author = {Zhu, Z. and Xu, S. and Tang, J. and Qu, M.},
title = {GraphVite: A High-Performance {CPU-GPU} Hybrid System for Node Embedding},
year = {2019},
publisher = {ACM},
address = {NY, USA},
booktitle = {The World Wide Web Conference},
pages = {2494–2504},
numpages = {11},
keywords = {scalability, parallel processing, graphics processing unit, Unsupervised node embedding},
location = {CA, USA},
series = {WWW ’19}
}

@article{roc,
author = {Fawcett, T.},
title = {An Introduction to ROC Analysis},
year = {2006},
issue_date = {June 2006},
publisher = {Elsevier Science Inc.},
address = {USA},
volume = {27},
number = {8},
issn = {0167-8655},
journal = {Pattern Recogn. Lett.},
month = jun,
pages = {861–874},
numpages = {14},
keywords = {ROC analysis, Classifier evaluation, Evaluation metrics}
}



@inproceedings{anomaly_detection,
author={R. {Hu} and C. C. {Aggarwal} and S. {Ma} and J. {Huai}},
booktitle={2016 IEEE 32nd Int. Conf. on Data Eng. (ICDE)},
title={An embedding approach to anomaly detection},
year={2016},
pages={385-396},
keywords={data analysis;social networking (online);network anomaly detection;structurally inconsistent nodes detection;social networks;network embedding approach;dimension reduction technique;community detection;Data mining;Algorithm design and analysis;Image edge detection;Social network services;Prediction algorithms;Optimization;Couplings},
month={May},
}

@inproceedings{hope,
author = {Ou, M. and Cui, P. and Pei, J. and Zhang, Z. and Zhu, W.},
title = {Asymmetric Transitivity Preserving Graph Embedding},
year = {2016},
publisher = {ACM},
address = {NY, USA},
booktitle = {Proc. 22nd Int. Conf. on Knowledge Discovery and Data Mining},
pages = {1105–1114},
numpages = {10},
keywords = {high-order proximity, asymmetric transitivity, directed graph, graph embedding},
location = {San Francisco, CA, USA},
series = {KDD ’16}
}

@misc{mile18,
    title={MILE: A Multi-Level Framework for Scalable Graph Embedding},
    author={J. Liang and S. Gurukar and S. Parthasarathy},
    year={2018},
    eprint={1802.09612},
    archivePrefix={arXiv},
    primaryClass={cs.AI}
}


@inproceedings{deepwalk,
author = {Perozzi, B. and Al-Rfou, R. and Skiena, S.},
title = {DeepWalk: Online Learning of Social Representations},
year = {2014},
publisher = {ACM},
address = {NY, USA},
booktitle = {Proc. 20th ACM SIGKDD Int. Conf. on Knowledge Discovery and Data Mining},
pages = {701–710},
numpages = {10},
keywords = {deep learning, learning with partial labels, latent representations, online learning, network classification, social networks},
location = {NY, USA},
series = {KDD ’14}
}

@inproceedings{grarep,
author = {Cao, S. and Lu, W. and Xu, Q.},
title = {GraRep: Learning Graph Representations with Global Structural Information},
year = {2015},
publisher = {ACM},
address = {NY, USA},
booktitle = {Proc. 24th ACM Int. Conf. on Info. and Knowledge Management},
pages = {891–900},
numpages = {10},
keywords = {algorithms, experimentation},
location = {Melbourne, Australia},
series = {CIKM ’15}
}



@Inproceedings{lem,
author = {Belkin, M. and Niyogi, P.},
title = {Laplacian Eigenmaps and Spectral Techniques for Embedding and Clustering},
year = {2001},
publisher = {MIT Press},
address = {Cambridge, MA, USA},
booktitle = {Proc. 14th Int. Conf. on Neural Information Processing Systems: Natural and Synthetic},
pages = {585–591},
numpages = {7},
location = {British Columbia, Canada},
series = {NIPS’01}
}



@article{roweis2000nonlinear,
  title={Nonlinear dimensionality reduction by locally linear embedding},
  author={Roweis, S. T. and Saul, L. K.},
  journal={science},
  volume={290},
  number={5500},
  pages={2323--2326},
  year={2000},
  publisher={AAAS}
}

@misc{harp,
    title={HARP: Hierarchical Representation Learning for Networks},
    author={H. Chen and B. Perozzi and Y. Hu and S. Skiena},
    year={2017},
    eprint={1706.07845},
    archivePrefix={arXiv},
    primaryClass={cs.SI}
}

@article{Goyal2018GraphET,
  title={Graph Embedding Techniques, Applications, and Performance: A Survey},
  author={P. Goyal and E. Ferrara},
  journal={Knowl. Based Syst.},
  year={2018},
  volume={151},
  pages={78-94}
}

@inproceedings{yt,
author = {Mislove, A. and Marcon, M. and Gummadi, K. P. and Druschel, P. and Bhattacharjee, B.},
title = {Measurement and Analysis of Online Social Networks},
year = {2007},
isbn = {9781595939081},
publisher = {ACM},
address = {New York, NY, USA},
booktitle = {Proceedings of the 7th ACM SIGCOMM Conference on Internet Measurement},
pages = {29–42},
numpages = {14},
keywords = {measurement, social networks, analysis},
location = {San Diego, California, USA},
series = {IMC ’07}
}

@article{hl,
author = {Meusel, R.},
year = {2015},
month = {08},
pages = {33-47},
title = {The Graph Structure in the Web – Analyzed on Different Aggregation Levels},
volume = {1},
journal = {Journal of Web Science},
}

@misc{snapnets,
  author       = {Jure Leskovec and Andrej Krevl},
  title        = {{SNAP Datasets}: {Stanford} Large Network Dataset Collection},
  howpublished = {\url{http://snap.stanford.edu/data}},
  month        = jun,
  year         = 2014
}

@Inproceedings{nr,
     title={The Network Data Repository with Interactive Graph Analytics and Visualization},
     author={R. A. Rossi and N. K. Ahmed},
     booktitle={AAAI},
     url={http://networkrepository.com},
     year={2015}
}

@misc{node2vec,
    title={node2vec: Scalable Feature Learning for Networks},
    author={A. Grover and J. Leskovec},
    year={2016},
    eprint={1607.00653},
    archivePrefix={arXiv},
    primaryClass={cs.SI}
}

@inproceedings{verse18,
author = {Tsitsulin, A. and Mottin, D. and Karras, P. and M\"{u}ller, E.},
title = {VERSE: Versatile Graph Embeddings from Similarity Measures},
year = {2018},
publisher = {IW3C2},
address = {Rep. and Canton of Geneva, CHE},
booktitle = {Proc. World Wide Web Conf.},
pages = {539–548},
numpages = {10},
keywords = {feature learning, graph representations, vertex similarity, graph embedding, information networks, node embedding},
location = {Lyon, France},
series = {WWW ’18}
}

@misc{pbg19,
    title={PyTorch-BigGraph: A Large-scale Graph Embedding System},
    author={A. Lerer and L. Wu and J. Shen and T. Lacroix and L. Wehrstedt and A. Bose and A. Peysakhovich},
    year={2019},
    eprint={1903.12287},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@inproceedings{LINE,
author = {Tang, J. and Qu, M. and Wang, M. and Zhang, M. and Yan, J. and Mei, Q.},
title = {LINE: Large-Scale Information Network Embedding},
year = {2015},
publisher = {IW3C2},
booktitle = {Proc. 24th Int. Conf. on World Wide Web},
pages = {1067–1077},
numpages = {11},
keywords = {dimension reduction, scalability, information network embedding, feature learning},
location = {Florence, Italy},
}
 
@Inproceedings{linkprediction,
author = {Liben-Nowell, D. and Kleinberg, J.},
title = {The Link Prediction Problem for Social Networks},
year = {2003},
publisher = {ACM},
address = {NY, USA},
booktitle = {Proc. 12th Int. Conf. on Information and Knowledge Management},
pages = {556–559},
numpages = {4},
keywords = {social networks, link analysis, link prediction},
location = {New Orleans, LA, USA},
series = {CIKM ’03}
}
  
 @Inproceedings{ordentlich2016network,
  title={Network-efficient distributed word2vec training system for large vocabularies},
  author={Ordentlich, E. and Yang, L. and Feng, A. and Cnudde, P. and Grbovic, M. and Djuric, N. and Radosavljevic, V. and Owens, Gavin},
  booktitle={Proc. 25th ACM Int. Conf. on Information and Knowledge Management},
  pages={1139--1148},
  year={2016},
  publisher={ACM}
}

@misc{swivel,
    title={Swivel: Improving Embeddings by Noticing What's Missing},
    author={N. Shazeer and R. Doherty and C. Evans and Chris Waterson},
    year={2016},
    eprint={1602.02215},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@inproceedings{hogwild,
author = {Niu, F. and Recht, B. and Re, C. and Wright, Stephen J.},
title = {HOGWILD! A Lock-Free Approach to Parallelizing Stochastic Gradient Descent},
year = {2011},
isbn = {9781618395993},
publisher = {Curran Associates Inc.},
address = {NY, USA},
booktitle = {Proc. 24th Int. Conf. on Neural Information Processing Systems},
pages = {693–701},
numpages = {9},
location = {Granada, Spain},
series = {NIPS’11}
}

@article{scikit-learn,
 title={Scikit-learn: Machine Learning in {P}ython},
 author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.
         and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.
         and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and
         Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
 journal={Journal of Machine Learning Research},
 volume={12},
 pages={2825--2830},
 year={2011}
}

@inproceedings{sdne, author = {Wang, Daixin and Cui, Peng and Zhu, Wenwu}, title = {Structural Deep Network Embedding}, year = {2016}, isbn = {9781450342322}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, abstract = {Network embedding is an important method to learn low-dimensional representations of vertexes in networks, aiming to capture and preserve the network structure. Almost all the existing network embedding methods adopt shallow models. However, since the underlying network structure is complex, shallow models cannot capture the highly non-linear network structure, resulting in sub-optimal network representations. Therefore, how to find a method that is able to effectively capture the highly non-linear network structure and preserve the global and local structure is an open yet important problem. To solve this problem, in this paper we propose a Structural Deep Network Embedding method, namely SDNE. More specifically, we first propose a semi-supervised deep model, which has multiple layers of non-linear functions, thereby being able to capture the highly non-linear network structure. Then we propose to exploit the first-order and second-order proximity jointly to preserve the network structure. The second-order proximity is used by the unsupervised component to capture the global network structure. While the first-order proximity is used as the supervised information in the supervised component to preserve the local network structure. By jointly optimizing them in the semi-supervised deep model, our method can preserve both the local and global network structure and is robust to sparse networks. Empirically, we conduct the experiments on five real-world networks, including a language network, a citation network and three social networks. The results show that compared to the baselines, our method can reconstruct the original network significantly better and achieves substantial gains in three applications, i.e. multi-label classification, link prediction and visualization.}, booktitle = {Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining}, pages = {1225–1234}, numpages = {10}, keywords = {deep learning, network analysis, network embedding}, location = {San Francisco, California, USA}, series = {KDD '16} }

@inproceedings{dngr, author = {Cao, Shaosheng and Lu, Wei and Xu, Qiongkai}, title = {Deep Neural Networks for Learning Graph Representations}, year = {2016}, publisher = {AAAI Press}, abstract = {In this paper, we propose a novel model for learning graph representations, which generates a low-dimensional vector representation for each vertex by capturing the graph structural information. Different from other previous research efforts, we adopt a random surfing model to capture graph structural information directly, instead of using the sampling-based method for generating linear sequences proposed by Perozzi et al. (2014). The advantages of our approach will be illustrated from both theorical and empirical perspectives. We also give a new perspective for the matrix factorization method proposed by Levy and Goldberg (2014), in which the pointwise mutual information (PMI) matrix is considered as an analytical solution to the objective function of the skip-gram model with negative sampling proposed by Mikolov et al. (2013). Unlike their approach which involves the use of the SVD for finding the low-dimensitonal projections from the PMI matrix, however, the stacked denoising autoencoder is introduced in our model to extract complex features and model non-linearities. To demonstrate the effectiveness of our model, we conduct experiments on clustering and visualization tasks, employing the learned vertex representations as features. Empirical results on datasets of varying sizes show that our model outperforms other stat-of-the-art models in such tasks.}, booktitle = {Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence}, pages = {1145–1152}, numpages = {8}, location = {Phoenix, Arizona}, series = {AAAI'16} }
